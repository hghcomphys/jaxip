{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TorchIP: Descriptor\n",
    "Examples on how to define and calulate descriptors from input structures (e.g. ASF). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "# import torchip\n",
    "from torchip.config import CFG\n",
    "from torchip.loaders import RunnerStructureLoader\n",
    "from torchip.potentials import NeuralNetworkPotential\n",
    "from torchip.loaders import RunnerStructureLoader as StructureLoader\n",
    "from torchip.loaders import read_structures\n",
    "from torchip.utils import gradient\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG.set(\"device\", \"cpu\")\n",
    "print(\"Device:\", CFG[\"device\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read structure\n",
    "base_dir = Path('.')\n",
    "loader = StructureLoader(Path(base_dir, \"input.data\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Potential\n",
    "pot = NeuralNetworkPotential(Path(base_dir, \"input.nn\"))\n",
    "# with Profiler(\"ASF scaling profiler\"):\n",
    "pot.fit_scaler(loader, filename=Path(base_dir, \"scaler.data\"))\n",
    "# pot.read_scaler(filename=Path(base_dir, \"scaler.data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str0 = read_structures(loader, between=(1, 1))[0]\n",
    "print(\"r_cutoff:\", pot.r_cutoff)\n",
    "\n",
    "# with Timer(\"Print scalers\"):\n",
    "for element in pot.elements:\n",
    "    \n",
    "    print(\"Element:\", element)\n",
    "    print(\"sample\", pot.scaler[element].sample)  \n",
    "    \n",
    "    for d in [\"min\", \"max\", \"mean\", \"sigma\"]:\n",
    "        \n",
    "        print(d, pot.scaler[element].__dict__[d].cpu().numpy())\n",
    "        val = pot.descriptor[element](str0, str0.select(element)[:1])\n",
    "        print(\"values\\n\", val.detach().cpu().numpy())\n",
    "        print(\"gradient\\n\", gradient(val[0], str0.position).detach().cpu().numpy()[:3]) \n",
    "        \n",
    "        # val = pot.scaler[element](val)\n",
    "        # print(\"scaled\", val.detach().numpy())\n",
    "        # print(gradient(val, str0.position)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "79f793817441a9b4f3336163bce28fb05f5fade87f8f747882a8ea5340683793"
  },
  "kernelspec": {
   "display_name": "Python (mlp)",
   "language": "python",
   "name": "mlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
