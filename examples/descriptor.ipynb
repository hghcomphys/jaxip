{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TorchIP: Descriptor\n",
    "An example notebook that shows how to define and calulate descriptors for structures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import torchip\n",
    "from torchip.datasets import RunnerStructureDataset\n",
    "from torchip.descriptors import AtomicSymmetryFunction  \n",
    "from torchip.potentials import NeuralNetworkPotential\n",
    "from torchip.utils import gradient, get_value\n",
    "from torchip.structure import ElementMap\n",
    "# from torchip.descriptors import CutoffFunction, G2, G3\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from matplotlib.pylab import plt\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchip.set_logging_level(logging.DEBUG)\n",
    "torchip.manual_seed(2020)\n",
    "torchip.device.DEVICE = torch.device(\"cpu\")\n",
    "# torchip.dtype.FLOAT = torch.float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read structure\n",
    "base_dir = './LJ' #Path('/home/hossein/n2p2/examples/nnp-train/H2O_RPBE-D3')\n",
    "structures = RunnerStructureDataset(Path(base_dir, \"input.data\")) \n",
    "structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structures[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Potential\n",
    "nnp = NeuralNetworkPotential(Path(base_dir, \"input.nn\"))\n",
    "print(\"potential cutoff radius:\", nnp.r_cutoff)\n",
    "nnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nnp.descriptor['O'].n_descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nnp.fit_scaler(structures)\n",
    "# !cat LJ/scaling.010.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsc_tip = defaultdict(list)\n",
    "for structure in structures:\n",
    "    structure.set_cutoff_radius(nnp.r_cutoff)\n",
    "    for element in nnp.elements:\n",
    "        #print(\"Element:\", element)\n",
    "        dsc = nnp.descriptor[element](structure)\n",
    "        # print(get_value(dsc).shape)\n",
    "        dsc_tip[element].append(get_value(dsc))\n",
    "        # scaled_dsc = nnp.scaler[element](dsc)\n",
    "        # print(get_value(scaled_dsc))\n",
    "    # break\n",
    "\n",
    "dsc_tip = {elem: np.array(dsc_tip[elem]) for elem in dsc_tip}\n",
    "for elem in dsc_tip:\n",
    "    print(elem, dsc_tip[elem].shape)\n",
    "    # print(dsc_tip[elem][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsc_n2p2 = defaultdict(list)\n",
    "with open(Path(base_dir, 'function.data'), 'r') as f:\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        n = int(line.rstrip(\"/n\"))\n",
    "        dsc_per_struct = defaultdict(list)\n",
    "        for _ in range(n):\n",
    "            line = f.readline().rstrip(\"/n\").split()\n",
    "            elem = ElementMap.get_element(int(line[0]))\n",
    "            dsc_per_struct[elem].append([float(v) for v in line[1:]])\n",
    "        f.readline()\n",
    "        [dsc_n2p2[elem].append(dsc_per_struct[elem]) for elem in dsc_per_struct]\n",
    "        # break\n",
    "\n",
    "dsc_n2p2 = {elem: np.array(dsc_n2p2[elem]) for elem in dsc_n2p2}\n",
    "for elem in dsc_n2p2:\n",
    "    print(elem, dsc_n2p2[elem].shape)\n",
    "    # print(dsc_tip[elem][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elem in dsc_tip:\n",
    "    print(elem)\n",
    "    assert np.allclose(dsc_n2p2[elem], dsc_tip[elem])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elem in dsc_tip:\n",
    "    plt.hist((dsc_n2p2[elem] - dsc_tip[elem]).flatten());\n",
    "    plt.xlabel('error'); plt.ylabel('count'); plt.title(elem);\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "79f793817441a9b4f3336163bce28fb05f5fade87f8f747882a8ea5340683793"
  },
  "kernelspec": {
   "display_name": "Python (torchip)",
   "language": "python",
   "name": "torhcip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
