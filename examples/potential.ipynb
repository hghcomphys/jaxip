{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lennard-Jones potential example\n",
    "An example notebook for reconstructing a high-dimensional neural network potential (HDNNP). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %env JAX_ENABLE_X64=1\n",
    "%env JAX_PLATFORM_NAME=cpu\n",
    "# %env JAX_DISABLE_JIT=1\n",
    "# %env JAX_DEBUG_NANS=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import mlpot\n",
    "from mlpot import logger\n",
    "from mlpot.datasets import RunnerStructureDataset, ToStructure\n",
    "from mlpot.potentials import NeuralNetworkPotential\n",
    "from mlpot.utils import gradient, get_value\n",
    "from mlpot.logger import LoggingContextManager\n",
    "\n",
    "import torch\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import matplotlib.pylab as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from ase.visualize import view\n",
    "from ase.io.vasp import write_vasp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlpot.set_logging_level(logging.DEBUG)\n",
    "mlpot.manual_seed(2022)\n",
    "mlpot.device.DEVICE = torch.device(\"cpu\")\n",
    "# mlpot.dtype.FLOAT = torch.float64\n",
    "# mlpot.set_logging_level(logging.DEBUG)\n",
    "\n",
    "# print(mlpot.__doc__)\n",
    "# print(f\"version: {mlpot.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dask cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dask.distributed import Client\n",
    "# from mlpot.config import TaskClient\n",
    "# TaskClient.client = Client(memory_limit='3GB', n_workers=2, processes=False, threads_per_worker=2, dashboard_address=':8791')\n",
    "# TaskClient.client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potdir = Path('./H2O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structures = RunnerStructureDataset(Path(potdir, \"input.data\"), persist=True) \n",
    "# structures = RunnerStructureDataset(Path(potdir, \"input.data\"), transform=ToStructure(r_cutoff=3.0), persist=True) \n",
    "print(\"Total number of structures:\", len(structures))\n",
    "structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = structures[0]\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s.calculate_distance(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlpot.descriptors.asf import ASF, G2, G3, CutoffFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfn = CutoffFunction(12.0)\n",
    "g2_1 = G2(cfn, 0.0, 0.001)\n",
    "g2_2 = G2(cfn, 0.0, 0.01)\n",
    "g3_1 = G3(cfn, 0.2, 1.0, 1.0, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asf = ASF('Ne')\n",
    "# asf.add(g2_1, 'Ne')\n",
    "# asf.add(g2_2, 'Ne')\n",
    "\n",
    "asf = ASF('H')\n",
    "asf.add(g2_1, 'H')\n",
    "asf.add(g2_2, 'H')\n",
    "asf.add(g3_1, 'H', 'H')\n",
    "asf.add(g3_1, 'H', 'O')\n",
    "\n",
    "asf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time asf(s, [1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time asf.grad(s, 1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add/remove per-atom energy offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# structure = structures[0]\n",
    "# atom_energy = {'O': 2.4, 'H': 1.2}\n",
    "\n",
    "# structure.add_energy_offset(atom_energy)\n",
    "# structure.total_energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logging context manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with LoggingContextManager(level=logging.DEBUG):\n",
    "# structures[0].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split train and validation structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation_split = 0.2\n",
    "# nsamples = len(structures)\n",
    "# split = int(np.floor(validation_split * nsamples))\n",
    "# train_structures, valid_structures = torch.utils.data.random_split(structures, lengths=[nsamples-split, split])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compare between structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with LoggingContextManager(level=logging.DEBUG):\n",
    "# structures[0].compare(structures[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualize a structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atoms = structures[5].to_ase_atoms()\n",
    "# atoms\n",
    "# view(atoms)\n",
    "# write_vasp('POSCAR', ase_atoms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnp = NeuralNetworkPotential(Path(potdir, \"input.nn\"))\n",
    "nnp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extrapolation warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nnp.set_extrapolation_warnings(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cProfile\n",
    "# profile = cProfile.Profile()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "         5663496 function calls (5662889 primitive calls) in 37.403 seconds\n",
    "\n",
    "   Ordered by: cumulative time\n",
    "\n",
    "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
    "        1    0.001    0.001   37.403   37.403 nnp.py:249(fit_scaler)\n",
    "       29    0.000    0.000   37.358    1.288 asf.py:49(__call__)\n",
    "       29    0.000    0.000   37.319    1.287 asf.py:73(<listcomp>)\n",
    "      222    0.003    0.000   37.319    0.168 asf.py:215(compute)\n",
    "      222    7.361    0.033   37.316    0.168 asf.py:102(_compute)\n",
    "   110787    5.359    0.000   20.242    0.000 angular.py:41(kernel)\n",
    "   335913    2.905    0.000   12.633    0.000 cutoff.py:36(__call__)\n",
    "   335913    2.583    0.000    7.496    0.000 cutoff.py:44(tanhu)\n",
    "   111231    1.673    0.000    7.166    0.000 structure.py:212(_calculate_distance)\n",
    "   111231    3.516    0.000    4.744    0.000 box.py:53(_apply_pbc)\n",
    "   671907    0.568    0.000    4.041    0.000 _tensor.py:26(wrapped)\n",
    "   335913    0.207    0.000    2.311    0.000 _tensor.py:637(__rsub__)\n",
    "   558375    2.223    0.000    2.223    0.000 {built-in method torch.where}\n",
    "   671907    2.163    0.000    2.163    0.000 {method 'pow' of 'torch._C._TensorBase' objects}\n",
    "   335913    2.104    0.000    2.104    0.000 {built-in method torch.rsub}\n",
    "   110787    1.377    0.000    1.377    0.000 {built-in method torch.inner}\n",
    "   335913    1.098    0.000    1.098    0.000 {built-in method torch.tanh}\n",
    "   335913    0.893    0.000    0.893    0.000 {built-in method torch.zeros_like}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile.runcall(nnp.fit_scaler, structures)\n",
    "# profile.print_stats(sort='cumtime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%time nnp.fit_scaler(structures)\n",
    "# nnp.load_scaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time history = nnp.fit_model(structures, epochs=100, validation_split=0.1) # validation_split=0.20)\n",
    "# %time history = nnp.fit_model(train_structures, epochs=10, validation_dataset=valid_structures)\n",
    "# %time history = profile(nnp.fit_model, structures, epochs=0, validation_split=0.20)\n",
    "# nnp.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nnp.extrapolation_warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss and error metrics\n",
    "\n",
    "### Observations\n",
    "- force values are fine\n",
    "- energy values are noticible different (w.r.t. N2P2) - probbaly the training algorithm has to be improved\n",
    "- need a toolset to make the N2P2 comparision and validation of forces, energy, descriptor, etc easier and faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(12,4))\n",
    "\n",
    "df = pd.DataFrame(history)\n",
    "df[[\"train_loss\", \"valid_loss\"]][:].plot(ax=ax[0]);\n",
    "df[[f\"train_energy_error\", f\"valid_energy_error\"]][:].plot(ax=ax[1]);\n",
    "df[[\"train_force_error\", f\"valid_force_error\"]][:].plot(ax=ax[2]);\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Energy and Forces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_metric = nnp.trainer.error_metric  \n",
    "\n",
    "df = defaultdict(list)\n",
    "for structure in structures:\n",
    "    \n",
    "    r = get_value(structure.calculate_distance(aid=0, neighbors=1))\n",
    "    df['r'].append(r[0])\n",
    "    err_metric.natoms = structure.natoms\n",
    "    \n",
    "    energy = nnp(structure)\n",
    "    E_pred = get_value(energy)\n",
    "    E_true = get_value(structure.total_energy)   \n",
    "    df['E_pred'].append(E_pred[0])\n",
    "    df['E_true'].append(E_true[0])\n",
    "    df['E_error'].append(float(get_value(err_metric(energy, structure.total_energy, structure.natoms))))\n",
    "    df['E_err'].append((E_true - E_pred)[0])\n",
    "    df['E_err/atom'].append((E_true - E_pred)[0]/structure.natoms)\n",
    "    \n",
    "    force = -gradient(energy, structure.position)\n",
    "    \n",
    "    F_pred = get_value(force)\n",
    "    F_true = get_value(structure.force)\n",
    "    \n",
    "    df['F_pred'].append(F_pred[0][0])\n",
    "    df['F_true'].append(F_true[0][0])\n",
    "    df['F_error'].append(float(get_value(err_metric(force, structure.force)))) \n",
    "    df['F_err'].append((F_true - F_pred)[0][0])\n",
    "    \n",
    "    # print(\"Predicted energy:\\n\", E_pred)\n",
    "    # print(\"True energy:\\n\", E_true)\n",
    "    # print(\"MSE:\\n\", mse(E_pred, E_true))\n",
    "    # print(\"RMSE:\\n\", rmse(E_pred, E_true))\n",
    "    # print(\"Predicted force: \\n\", F_pred )\n",
    "    # print(\"True force:\\n\", F_true)\n",
    "    # print(\"MSE:\\n\", mse(F_pred, F_true))\n",
    "    # print(\"RMSE:\\n\", rmse(F_pred, F_true))\n",
    "    \n",
    "df = pd.DataFrame(df)\n",
    "print(f\"Max  --> E_error={df['E_error'].max():6f} F_error={df['F_error'].max():6f}\")\n",
    "print(f\"Mean --> E_error={df['E_error'].mean():6f} F_error={df['F_error'].mean():6f}\")\n",
    "print()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 2, figsize=(11,8))\n",
    "EV_TO_HARTREE = 0.0367493\n",
    "ENERGY_ERR    = 2.0E-3*EV_TO_HARTREE  # 2.0 meV/atom\n",
    "FORCE_ERR     = 0.1*EV_TO_HARTREE     # 0.1 eV/Bohr\n",
    "\n",
    "df.plot(x='r', y=['E_pred', 'E_true'], ax=ax[0][0], style='.-', lw=0.5)\n",
    "df.plot(x='r', y=['E_error'], ax=ax[1][0], style='.-', lw=0.5); \n",
    "df.plot.hist(y=['E_err/atom'], ax=ax[2][0])\n",
    "\n",
    "df.plot(x='r', y=['F_pred', 'F_true'], ax=ax[0][1], style='.-', lw=0.5)\n",
    "df.plot(x='r', y=['F_error'], ax=ax[1][1], style='.-', lw=0.5)\n",
    "df.plot.hist(y=['F_err'], ax=ax[2][1]);\n",
    "\n",
    "if str(err_metric) == \"RMSEpa\":\n",
    "    ax[1][0].axhline(ENERGY_ERR, ls='--', c='r'); print(f\"Eenergy Thrsh.: {ENERGY_ERR:.10f}\")\n",
    "    ax[1][1].axhline(FORCE_ERR, ls='--', c='r');  print(f\"Force   Thrsh.: {FORCE_ERR:.10f}\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "79f793817441a9b4f3336163bce28fb05f5fade87f8f747882a8ea5340683793"
  },
  "kernelspec": {
   "display_name": "Python (torchip)",
   "language": "python",
   "name": "torhcip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
