{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytoch performance experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "from time import perf_counter\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Performance scaling\n",
    "\n",
    "Observations:\n",
    "- data type `double` is slower that `float`\n",
    "- calculations on a powerful GPU, such as A100, runs `60` times faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel(inp):\n",
    "    x = 0\n",
    "    for _ in range(100):\n",
    "        x += torch.sin(inp)\n",
    "    return x\n",
    "\n",
    "def run(device=device, dtype=dtype, size=N):\n",
    "    #print(f\"size  : {size}\")\n",
    "    #print(f\"device: {device}\")\n",
    "    #print(f\"dtype : {dtype}\")\n",
    "    start = perf_counter()\n",
    "    inp = torch.eye(size, requires_grad=True, dtype=dtype)\n",
    "    inp2 = inp.to(device)\n",
    "    out = kernel(inp2)\n",
    "    out.backward(torch.ones_like(inp2), retain_graph=True)\n",
    "    stop = perf_counter()\n",
    "    #print(f\"Gradient {inp.grad}\")\n",
    "    return stop-start\n",
    "\n",
    "# %time run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = defaultdict(list)\n",
    "for size in np.logspace(1, 12, 12, base=2, dtype=np.int32):\n",
    "    print(f\"size: {size}\")\n",
    "    df['size'].append(size)\n",
    "    df['cpu-float'].append( run('cpu'   , torch.float , size))\n",
    "    df['gpu-float'].append( run('cuda:0', torch.float , size))\n",
    "    df['cpu-double'].append(run('cpu'   , torch.double, size))\n",
    "    df['gpu-double'].append(run('cuda:0', torch.double, size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df)\n",
    "df.plot(x='size', y=['cpu-float', 'gpu-float', 'cpu-double', 'gpu-double'])\n",
    "plt.ylabel('elapsed time')\n",
    "\n",
    "df['speedup-float'] = df['cpu-float']/df['gpu-float']\n",
    "df['speedup-double'] = df['cpu-double']/df['gpu-double']\n",
    "df.plot.bar(x='size', y=['speedup-double', 'speedup-float'])\n",
    "plt.axhline(1.0, ls='--', c='k')\n",
    "plt.ylabel('speed up over gpu')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torch script (jit)\n",
    "\n",
    "Observations:\n",
    "- not much performance improvement is observed using the `torch.jit.script`\n",
    "- no multi processing is observed by `Pytorch`\n",
    "- but multi-processing is possible usin `Dask` client\n",
    "- Dask cannot handle scripted funciton (picke error)\n",
    "- Dask with GPU client is slow and multi-workers consumes more memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @torch.jit.script\n",
    "def kernel(x, y, device: torch.device):\n",
    "    r = torch.empty(x.shape).to(device)\n",
    "    for _ in range(10000):\n",
    "        if x.max() > y.max():\n",
    "            r = r + torch.sin(x+y)\n",
    "        else:\n",
    "            r = r + torch.cos(x-y)\n",
    "    return r\n",
    "\n",
    "@torch.jit.script\n",
    "def kernel_jit(x, y, device: torch.device):\n",
    "    return kernel(x, y, device)\n",
    "\n",
    "print(type(kernel_jit))  # torch.jit.ScriptFunction\n",
    "\n",
    "# See the compiled graph as Python code\n",
    "print(kernel_jit.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(device, dtype, size, kernel):\n",
    "    #print(f\"size  : {size}\")\n",
    "    #print(f\"device: {device}\")\n",
    "    #print(f\"dtype : {dtype}\")\n",
    "    start = perf_counter()\n",
    "    inp1 = torch.rand(size, requires_grad=True, dtype=dtype)\n",
    "    inp2 = torch.rand(size, requires_grad=True, dtype=dtype)\n",
    "    out = kernel(inp1.to(device), inp2.to(device), device)\n",
    "    out.backward(torch.ones_like(inp2).to(device), retain_graph=True)\n",
    "    stop = perf_counter()\n",
    "    #print(f\"Gradient {inp.grad}\")\n",
    "    return stop-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = defaultdict(list)\n",
    "size = 1000\n",
    "for _ in range(10):\n",
    "    print(_)\n",
    "    df['attempt'].append(_+1)\n",
    "    df['cpu'].append( run('cpu'   , torch.double , size, kernel))\n",
    "    df['gpu'].append( run('cuda:0', torch.double , size, kernel))\n",
    "    df['cpu-jit'].append( run('cpu'   , torch.double , size, kernel_jit))\n",
    "    df['gpu-jit'].append( run('cuda:0', torch.double , size, kernel_jit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df)\n",
    "# df.plot(x='attempt')\n",
    "plt.ylabel('elapsed time')\n",
    "df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dask client (multi-process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, fire_and_forget\n",
    "from dask_cuda import LocalCUDACluster\n",
    "\n",
    "client = Client(memory_limit='3GB', n_workers=4, processes=True, threads_per_worker=1, dashboard_address=':8791')\n",
    "\n",
    "# cluster = LocalCUDACluster(n_workers=1, threads_per_worker=1, dashboard_address=':8791',\n",
    "#                               memory_limit=\"auto\",\n",
    "#                               device_memory_limit=\"auto\", # memory spilling\n",
    "#                               #rmm_pool_size=\"5GB\",\n",
    "#                               #rmm_managed_memory=True,\n",
    "#                               #silence_logs=False,\n",
    "#                               local_directory=\"/tmp/\", \n",
    "#                               #enable_nvlink=True,\n",
    "#                               ) # See https://docs.rapids.ai/api/dask-cuda/nightly/api.html\n",
    "# client = Client(cluster)\n",
    "\n",
    "display(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Future: tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=1000\n",
    "device = torch.device('cpu')\n",
    "dtype = torch.double\n",
    "\n",
    "for _ in range(100):\n",
    "    inp1 = torch.rand(size, requires_grad=True, dtype=dtype)\n",
    "    inp2 = torch.rand(size, requires_grad=True, dtype=dtype)\n",
    "    future = client.submit(kernel, inp1.to(device), inp2.to(device), device)\n",
    "    fire_and_forget(future)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Future: structures\n",
    "\n",
    "Observations:\n",
    "- Dask cannot directly parallize a kernel with generic input class such as Structure.\n",
    "- As a solution, the kernel's inputs have to be translated in form of arrays or tensors. \n",
    "- Also defining a Kernel class which takes care of unnecessary inputs are very useful and an elegant design. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import torchip as tp\n",
    "from torchip import logger\n",
    "from torchip.datasets import RunnerStructureDataset, ToStructure\n",
    "from torchip.potentials import NeuralNetworkPotential\n",
    "\n",
    "tp.device.DEVICE = \"cpu\"\n",
    "\n",
    "import torch\n",
    "import time\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potdir = Path(\"../examples/LJ\")\n",
    "\n",
    "structures = RunnerStructureDataset(Path(potdir, \"input.data\"), persist=True) \n",
    "structure0 = structures[4]\n",
    "\n",
    "nnp = NeuralNetworkPotential(Path(potdir, \"input.nn\"))\n",
    "descriptor = nnp.descriptor[\"Ne\"]\n",
    "scaler = nnp.scaler[\"Ne\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# structure0.calculate_distance(aid=0, neighbors=1, detach=False, return_diff=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "\n",
    "class Box:\n",
    "    def __init__(self, lattice):\n",
    "        self.lattice = lattice\n",
    "    \n",
    "    @staticmethod\n",
    "    def _apply_pbc(dx, lat):\n",
    "        for i in range(3):\n",
    "            l = lat[i, i]\n",
    "            dx[..., i] = torch.where(dx[..., i] >  0.5E0*l, dx[..., i] - l, dx[..., i])\n",
    "            dx[..., i] = torch.where(dx[..., i] < -0.5E0*l, dx[..., i] + l, dx[..., i])\n",
    "        return dx\n",
    "    \n",
    "    def apply_pbc(self, dx):\n",
    "        return Box._apply_pbc(dx, self.lattice)\n",
    "        \n",
    "\n",
    "class Structure_:\n",
    "    \n",
    "    @staticmethod\n",
    "    def _calculate_distance(\n",
    "            pos: Tensor,\n",
    "            aid: int, \n",
    "            lat: Tensor = None,\n",
    "            detach: bool = False, \n",
    "            neighbors = None, \n",
    "            difference: bool = False\n",
    "        ) -> Tensor: # TODO: also tuple?\n",
    "        \"\"\"\n",
    "        This method calculates an array of distances of all atoms existing in the structure from an input atom. \n",
    "        TODO: input pbc flag, using default pbc from global configuration\n",
    "        TODO: also see torch.cdist\n",
    "        \"\"\"   \n",
    "        x = pos.detach() if detach else pos\n",
    "        x = x[neighbors] if neighbors else x \n",
    "        x = torch.unsqueeze(x, dim=0) if x.ndim == 1 else x  # for when neighbors index is only a number\n",
    "        dx = pos[aid] - x  # FIXME: detach?\n",
    "\n",
    "        # Apply PBC along x,y,and z directions if lattice info is provided \n",
    "        if lat is not None:\n",
    "            dx = Box._apply_pbc(dx, lat) # using broadcasting\n",
    "\n",
    "        # Calculate distance from dx tensor\n",
    "        distance = torch.linalg.vector_norm(dx, dim=1)\n",
    "\n",
    "        return distance if not difference else (distance, dx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchip.structure.box import Box\n",
    "\n",
    "class Kernel:\n",
    "    def __init__(self, func, dist, pbc):\n",
    "        self.func = func\n",
    "        self.dist = dist\n",
    "        self.pbc = pbc\n",
    "        \n",
    "\n",
    "    def __call__(self, x, at, dtype=None, device=None, emap=None, lat=None):\n",
    "        for i in range(10000):\n",
    "            self.func(x)\n",
    "            self.func(at)\n",
    "        if emap:\n",
    "            emap[int(at[0])]\n",
    "        if self.dist:\n",
    "            dx = self.dist(x, aid=0, neighbors=1)\n",
    "            print(dx)\n",
    "        if lat:\n",
    "            self.pbc(dx, lat)\n",
    "        # time.sleep(0.1)\n",
    "\n",
    "kernel = Kernel(torch.max, dist=Structure_._calculate_distance, pbc=Box._apply_pbc)\n",
    "for structure in structures:\n",
    "    tensors = [structure.position, structure.atype]\n",
    "    params = {\n",
    "        'dtype': torch.double, \n",
    "        'device': 'cpu', \n",
    "        'emap': structure.element_map.atype_to_element,\n",
    "        'lat': structure.box.lattice if structure.box else None,\n",
    "    }\n",
    "    # client.scatter(tensors, broadcast=True)  \n",
    "    future = client.submit(kernel, *tensors, **params)\n",
    "    fire_and_forget(future)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from dask import delayed\n",
    "\n",
    "# @torch.jit.script\n",
    "def fun(x: torch.Tensor) -> torch.Tensor:\n",
    "    return x\n",
    "\n",
    "# fn = delayed(fun, pure=False)  # works\n",
    "fn = delayed(fun, pure=True)  # causes error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fn(torch.rand(size, requires_grad=True, dtype=dtype)).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch scalar\n",
    "\n",
    "Observations:\n",
    "- the torch scalar is slighly faster than the generic python scalar for some cases.\n",
    "- it's expected that this difference increases as having more scalar vs. tensor operations specifically on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=10000\n",
    "device = torch.device('cuda')\n",
    "dtype = torch.double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(size, dtype=dtype, device=device, requires_grad=True)\n",
    "st = torch.tensor(4, dtype=dtype, device=device )\n",
    "s  = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel(x, s):\n",
    "    for _ in range(5000):\n",
    "        x = torch.where(torch.sin(x) < 0.5, s*x, s*x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile(kernel, *args, **kwargs):\n",
    "    with torch.profiler.profile(\n",
    "        activities=[\n",
    "            torch.profiler.ProfilerActivity.CPU,\n",
    "            torch.profiler.ProfilerActivity.CUDA,\n",
    "        ]\n",
    "    ) as p:\n",
    "        kernel(*args, **kwargs)\n",
    "        \n",
    "    print(p.key_averages().table(\n",
    "        sort_by=\"self_cuda_time_total\", row_limit=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "profile(kernel, x, st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# profile(kernel, x, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pin memory\n",
    "\n",
    "A relevant link: https://spell.ml/blog/pytorch-training-tricks-YAnJqBEAACkARhgD\n",
    "\n",
    "Observations:\n",
    "- not much difference when pin_memory flag is activated\n",
    "- multi processing has to be activate with at least 4 workers\n",
    "- pin mmeory has to be taken account when host-device memcopy is the computational bottle neck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision, torch, time\n",
    "import numpy as np\n",
    " \n",
    "pin_memory = False\n",
    "\n",
    "batch_size = 4098 # bigger memory transfers to make their cost more noticable\n",
    "n_workers = 4 # parallel workers to free up the main thread and reduce data decoding overhead\n",
    "\n",
    "train_dataset =torchvision.datasets.CIFAR10(\n",
    "    root='cifar10_pytorch',\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ")   \n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    pin_memory=pin_memory,\n",
    "    num_workers=n_workers\n",
    ")   \n",
    "print('pin_memory:', pin_memory)\n",
    "times = []\n",
    "n_runs = 5\n",
    "\n",
    "def work():\n",
    "    # emulates the CPU work done\n",
    "    time.sleep(0.01)\n",
    "\n",
    "for i in range(n_runs):\n",
    "    st = time.time()\n",
    "    for bx, by in train_dataloader:\n",
    "       bx, by = bx.cuda(non_blocking=pin_memory), by.cuda(non_blocking=pin_memory)\n",
    "       work()\n",
    "    times.append(time.time() - st)\n",
    "print('average time:', np.mean(times))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torchip)",
   "language": "python",
   "name": "torhcip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
